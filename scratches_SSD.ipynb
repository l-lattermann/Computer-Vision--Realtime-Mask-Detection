{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.9.6' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import re\n",
    "from scripts import tf_text_graph_common\n",
    "import tensorflow  as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from scripts.video_source import VideoSource\n",
    "from scripts import tf_text_graph_ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_graph = \"models/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\"\n",
    "saved_model = \"models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\"\n",
    "pipeline_config = \"models/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromTensorflow(saved_model, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output path\n",
    "#config_file = \"models/ssd_mobilenet_v2_coco_2018_03_29/saved_model/ssd_mobilenet_v2_coco_2018_03_29.pbtxt\"\n",
    "#\n",
    "## creat ssd graph\n",
    "#tf_text_graph_ssd.createSSDGraph(model_file, pipeline_config, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "with open(\"models/ssd_mobilenet_v2_coco_2018_03_29/labels.txt\", \"r\") as f:\n",
    "    labels = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv.dnn.readNetFromTensorflow(model_file, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(net, im):\n",
    "    dim = 300\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(im, size=(dim, dim), swapRB=True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    objects = net.forward()\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text(im, text, x, y):\n",
    "    # Get text size and baseline\n",
    "    text_size = cv.getTextSize(text, cv.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "    dim = text_size[0]\n",
    "    baseline = text_size[1]\n",
    "    \n",
    "    # Draw a filled rectangle for text background\n",
    "    cv.rectangle(im, (x, y - dim[1] - baseline), (x + dim[0], y+baseline), (255, 255, 255), cv.FILLED)\n",
    "    \n",
    "    # Overlay the text on top\n",
    "    cv.putText(im, text, (x, y - baseline), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_objects_static(im, objects, threshold=0.25):\n",
    "\n",
    "    rows = im.shape[0]; cols = im.shape[1]\n",
    "\n",
    "    for i in range(objects.shape[2]):\n",
    "\n",
    "        class_id = int(objects[0, 0, i, 1])\n",
    "        score = float(objects[0, 0, i, 2])\n",
    "\n",
    "        # Retrieve original coordinates\n",
    "        x = int(objects[0, 0, i, 3] * cols)\n",
    "        y = int(objects[0, 0, i, 4] * rows)\n",
    "        w = int(objects[0, 0, i, 5] * cols) - x\n",
    "        h = int(objects[0, 0, i, 6] * rows) - y\n",
    "\n",
    "        # Check if score is above threshold\n",
    "        if score > threshold:\n",
    "\n",
    "            # Display bounding box\n",
    "            display_text(im, f\"  {labels[class_id-1]} {round(score,2)}  \", x, y)\n",
    "            cv.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Convert image to RGB\n",
    "    mp_img = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(30, 10)); plt.imshow(mp_img); plt.axis('off'), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_objects_live(im, objects, threshold=0.25):\n",
    "\n",
    "    rows = im.shape[0]; cols = im.shape[1]\n",
    "\n",
    "    for i in range(objects.shape[2]):\n",
    "\n",
    "        class_id = int(objects[0, 0, i, 1])\n",
    "        score = float(objects[0, 0, i, 2])\n",
    "\n",
    "        # Retrieve original coordinates\n",
    "        x = int(objects[0, 0, i, 3] * cols)\n",
    "        y = int(objects[0, 0, i, 4] * rows)\n",
    "        w = int(objects[0, 0, i, 5] * cols) - x\n",
    "        h = int(objects[0, 0, i, 6] * rows) - y\n",
    "\n",
    "        # Check if score is above threshold\n",
    "        if score > threshold:\n",
    "\n",
    "            # Display bounding box\n",
    "            display_text(im, f\"  {labels[class_id-1]} {round(score,2)}  \", x, y)\n",
    "            cv.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Convert image to RGB\n",
    "    mp_img = cv.cvtColor(im, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Person tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_persons(im):\n",
    "\n",
    "    dim = 300\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(im, size=(dim, dim), swapRB=True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    filtered_detections = net.forward()\n",
    "\n",
    "    # Drop all that are not persons\n",
    "    detections = filtered_detections[0, 0, :, :]  # Shape: (100, 7)\n",
    "    filtered_detections = detections[detections[:, 1] == 1]  # Filter class 1 (person)\n",
    "    print(filtered_detections.shape)\n",
    "    # Get image dimensions\n",
    "    rows = im.shape[0]; cols = im.shape[1]\n",
    "\n",
    "    # Create a list to store cropped images\n",
    "    crops = []\n",
    "    for i in range(filtered_detections.shape[0]):\n",
    "        class_id = int(filtered_detections[i, 1])\n",
    "        score = float(filtered_detections[i, 2])\n",
    "        x = int(filtered_detections[i, 3] * cols)\n",
    "        y = int(filtered_detections[i, 4] * rows)\n",
    "        w = int(filtered_detections[i, 5] * cols) - x\n",
    "        h = int(filtered_detections[i, 6] * rows) - y\n",
    "\n",
    "        # Check if score is above threshold\n",
    "        if score > 0.5 and class_id == 1:\n",
    "            crops.append(im[y:y+h//3, x+w//5:x+w-w//5])\n",
    "\n",
    "        # Get the faces by cropping top third\n",
    "\n",
    "\n",
    "    return crops\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_person_live(im, objects, threshold=0.25):\n",
    "\n",
    "    rows = im.shape[0]; cols = im.shape[1]\n",
    "\n",
    "    for i in range(objects.shape[2]):\n",
    "\n",
    "        if int(objects[0, 0, i, 1]) == 1:\n",
    "            class_id = int(objects[0, 0, i, 1])\n",
    "            score = float(objects[0, 0, i, 2])\n",
    "\n",
    "            # Retrieve original coordinates\n",
    "            x = int(objects[0, 0, i, 3] * cols)\n",
    "            y = int(objects[0, 0, i, 4] * rows)\n",
    "            w = int(objects[0, 0, i, 5] * cols) - x\n",
    "            h = int(objects[0, 0, i, 6] * rows) - y\n",
    "\n",
    "            # Check if score is above threshold\n",
    "            if score > threshold:\n",
    "\n",
    "                # Display bounding box\n",
    "                display_text(im, f\"  {labels[class_id-1]} {round(score,2)}  \", x, y)\n",
    "                cv.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "\n",
    "    im = cv.imread(f\"image_data/{i}.jpg\")\n",
    "    filtered_detections = detect_objects(net, im)\n",
    "    #display_objects_static(im, filtered_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Webcam inpunt detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create video source\n",
    "#cap = VideoSource(0)\n",
    "#\n",
    "## Show video\n",
    "#win_name = \"Object Detection\"\n",
    "#cv.namedWindow(win_name, cv.WINDOW_FREERATIO)\n",
    "#\n",
    "#while cv.waitKey(1) < 0:\n",
    "#    has_frame, frame = cap.read()\n",
    "#\n",
    "#    if not has_frame:\n",
    "#        \n",
    "#        # release the video capture object\n",
    "#        cap.release()\n",
    "#\n",
    "#        # close all windows\n",
    "#        cv.destroyAllWindows()\n",
    "#        break\n",
    "#\n",
    "#    objects = detect_objects(net, frame)\n",
    "#    display_person_live(frame, objects)\n",
    "#\n",
    "#    cv.imshow(win_name, frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test person cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv.imread(\"image_data/persons2.jpeg\")\n",
    "crops = crop_persons(im)\n",
    "\n",
    "for i in range(len(crops)):\n",
    "    cv.imshow(f\"Person {i}\", crops[i])\n",
    "    mp_img = cv.cvtColor(crops[i], cv.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(30, 10)); plt.imshow(mp_img); plt.axis('off'), plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
